{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46be11c-94b6-4ccc-b937-2bbd41894dd1",
   "metadata": {},
   "source": [
    "## Neural Network and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b85fa07e-ed46-42e8-ba60-385546df373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d8d8c4-09e8-49bf-9d3c-7fcec89884e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f7a9d-f17e-48e6-a0a9-b51281fcb7ec",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d16071-3076-4955-95a1-199c1fd47674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25999e47-b772-4799-a11e-19d5a1914f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 74, 74, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391fd1c0-95e9-4f0b-b470-6d5fc3fdea77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 175232)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f183782b-fcd2-4b20-a14d-ac11460faea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\\\n",
    "             optimizer=optimizers.SGD(learning_rate=0.002, momentum=0.8),\\\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd67bd4-ba19-4f4b-9759-99637ba2c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d6e6b-d6e0-4029-b2bb-613de8f52d6a",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbf3887e-0706-43aa-a49f-c82ec696bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f432ec9d-b3cb-4f4d-98fb-0f3336f20e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_datagen.flow_from_directory(\n",
    "    './data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = val_datagen.flow_from_directory(\n",
    "    './data/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62ed41fe-35b2-443c-8edc-61038293d7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 20:38:11.996718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-20 20:38:12.809201: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f36840e3180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-20 20:38:12.809233: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5\n",
      "2023-11-20 20:38:12.869005: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 6s 25ms/step - loss: 0.6737 - acc: 0.5725 - val_loss: 0.6283 - val_acc: 0.6144\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.6273 - acc: 0.6418 - val_loss: 0.5960 - val_acc: 0.6623\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.5794 - acc: 0.6970 - val_loss: 0.5975 - val_acc: 0.6601\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.5527 - acc: 0.7234 - val_loss: 0.5527 - val_acc: 0.7473\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 4s 23ms/step - loss: 0.5165 - acc: 0.7566 - val_loss: 0.5459 - val_acc: 0.7157\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.4808 - acc: 0.7890 - val_loss: 0.5432 - val_acc: 0.7342\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.4531 - acc: 0.7958 - val_loss: 0.5037 - val_acc: 0.7691\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 4s 21ms/step - loss: 0.4427 - acc: 0.8066 - val_loss: 0.5142 - val_acc: 0.7593\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 4s 19ms/step - loss: 0.3967 - acc: 0.8338 - val_loss: 0.5705 - val_acc: 0.7157\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 4s 20ms/step - loss: 0.3685 - acc: 0.8431 - val_loss: 0.4948 - val_acc: 0.7789\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bc40d-ddac-4bbf-b54f-7459d8ac9ab2",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fabd206b-0d10-4268-a1cc-0fd48fb6e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9be03c8-c9c8-4e4b-a712-23b24d0db7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77277672290802"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_median = np.median(acc)\n",
    "acc_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff44435-f728-4c26-8a0e-e66f971834bf",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89056ff7-88ab-47f3-b2d2-74b6301e6ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09417467753605775"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4ab7f-41ec-4ae9-8be4-c200e19a8681",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c734ce43-fab9-4763-9527-80b337d72959",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d74b181e-959d-464e-bf9b-b73b605b1df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "091d7a13-1952-4557-b75a-062a09cb8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb771977-6b7f-45f8-b4ac-4142d7e355a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('./data/train',\n",
    "                                                    target_size=(150, 150), \n",
    "                                                    batch_size=32, \n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a2cd1e0-7222-4c66-8ecc-ea5c6fe9fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    './data/test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cae114f-7dae-412c-b79f-efeb6fd78a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "115/115 [==============================] - 14s 118ms/step - loss: 0.4522 - acc: 0.7960 - val_loss: 0.4569 - val_acc: 0.7865\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 13s 116ms/step - loss: 0.4552 - acc: 0.7914 - val_loss: 0.5267 - val_acc: 0.7680\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 13s 116ms/step - loss: 0.4420 - acc: 0.8072 - val_loss: 0.4741 - val_acc: 0.7876\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 13s 116ms/step - loss: 0.4389 - acc: 0.8058 - val_loss: 0.4608 - val_acc: 0.7821\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 13s 117ms/step - loss: 0.4452 - acc: 0.8069 - val_loss: 0.4535 - val_acc: 0.7898\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 13s 115ms/step - loss: 0.4360 - acc: 0.8001 - val_loss: 0.4449 - val_acc: 0.7930\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 14s 118ms/step - loss: 0.4383 - acc: 0.7993 - val_loss: 0.4349 - val_acc: 0.8072\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 14s 119ms/step - loss: 0.4320 - acc: 0.8066 - val_loss: 0.4437 - val_acc: 0.7887\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 13s 116ms/step - loss: 0.4353 - acc: 0.8072 - val_loss: 0.4382 - val_acc: 0.7930\n",
      "Epoch 10/10\n",
      "115/115 [==============================] - 13s 117ms/step - loss: 0.4357 - acc: 0.8026 - val_loss: 0.5071 - val_acc: 0.7549\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c1f011e-be6f-45fb-852c-90a7d27472b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_aug = history.history['acc']\n",
    "val_acc_aug = history.history['val_acc']\n",
    "loss_aug = history.history['loss']\n",
    "val_loss_aug = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8c89699-5d03-428a-8f35-95dd533f98d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77277672290802"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_median = np.median(acc)\n",
    "acc_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57e0cadc-b3ea-4688-81c9-8aed80cb47e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4640910685062408"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_loss_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a339ab-8d21-4c55-9ef1-067f6876672f",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d5b8766-d913-435d-9c05-75dbd200834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859476953744888"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_acc_aug[6:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1a953-89b1-4398-9033-6938ec7d06cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
